{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "058de3b3-0a4f-42e6-b512-7756ff894e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b86697fc-9edf-4070-85f0-45f3ca3542aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_time(start, end):\n",
    "    print(f\"\\ntrain time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6709f273-0640-4c3a-885c-6c018e31a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"drug_consumption.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9003efa4-5a12-49c0-96d3-6ff473ba935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee8ee2de-b1a5-4222-b12b-9c889bab9084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65b0c592-a967-4bad-b331-ebe6bb4f1614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Gender', 'Education', 'Country', 'Ethnicity', 'Nscore',\n",
       "       'Escore', 'Oscore', 'Ascore', 'Cscore', 'Impulsive', 'SS', 'Alcohol',\n",
       "       'Amphet', 'Amyl', 'Benzos', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack',\n",
       "       'Ecstasy', 'Heroin', 'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms',\n",
       "       'Nicotine', 'Semer', 'VSA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c937754b-0248-483c-b2cb-3926427be9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age          float64\n",
       "Gender       float64\n",
       "Education    float64\n",
       "Country      float64\n",
       "Ethnicity    float64\n",
       "Nscore       float64\n",
       "Escore       float64\n",
       "Oscore       float64\n",
       "Ascore       float64\n",
       "Cscore       float64\n",
       "Impulsive    float64\n",
       "SS           float64\n",
       "Alcohol       object\n",
       "Amphet        object\n",
       "Amyl          object\n",
       "Benzos        object\n",
       "Caff          object\n",
       "Cannabis      object\n",
       "Choc          object\n",
       "Coke          object\n",
       "Crack         object\n",
       "Ecstasy       object\n",
       "Heroin        object\n",
       "Ketamine      object\n",
       "Legalh        object\n",
       "LSD           object\n",
       "Meth          object\n",
       "Mushrooms     object\n",
       "Nicotine      object\n",
       "Semer         object\n",
       "VSA           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f937e960-9732-42f6-9a7d-014a2b529daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.select_dtypes(include=['number']).columns\n",
    "labels = df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "097758b4-db5b-4efd-b846-72099b76cb26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Gender', 'Education', 'Country', 'Ethnicity']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#{i:len(df[i].value_counts()) for i in num_cols}\n",
    "cat_cols = [i for i in features if len(df[i].value_counts()) < 10]\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5824ab-454f-4247-a2cd-f8ca4fa2f05a",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb3759b4-1af0-437b-8603-1945a6b98d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-0.95197: '18 - 24',\n",
       " -0.07854: '25 - 34',\n",
       " 0.49788: '35 - 44',\n",
       " 1.09449: '45 - 54',\n",
       " 1.82213: '55 - 64',\n",
       " 2.59171: '65+'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 24\n",
    "temp = [[18 if i == 0 else start + 10*(i-1) + 1, start + 10*i] for i in range(5)]\n",
    "age_groups = [f\"{i[0]} - {i[1]}\" for i in temp]\n",
    "age_groups.append(\"65+\")\n",
    "Age_map = {j:age_groups[i] for i, j in enumerate(sorted(df[cat_cols[0]].unique()))}\n",
    "Age_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df723ea-685e-4892-bb86-7f0d2b265f51",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dda052b8-2da2-4242-a627-577a83c685d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.48246: 'Female', -0.48246: 'Male'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gender_map = dict(zip(df[cat_cols[1]].unique(), [\"Female\", \"Male\"]))\n",
    "Gender_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71530bf-80d0-4362-a414-0ff853a63514",
   "metadata": {},
   "source": [
    "### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "906fd221-cba8-4051-892f-09fb10b082ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-2.43591: 'Left School Before 16 years',\n",
       " -1.7379: 'Left School at 16 years',\n",
       " -1.43719: 'Left School at 17 years',\n",
       " -1.22751: 'Left School at 18 years',\n",
       " -0.61113: 'Some College,No Certificate Or Degree',\n",
       " -0.05921: 'Professional Certificate/ Diploma',\n",
       " 0.45468: 'University Degree',\n",
       " 1.16365: 'Masters Degree',\n",
       " 1.98437: 'Doctorate Degree'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_groups = [\"Left School Before 16 years\",\n",
    "\"Left School at 16 years\",\n",
    "\"Left School at 17 years\",\n",
    "\"Left School at 18 years\",\n",
    "\"Some College,No Certificate Or Degree\",\n",
    "\"Professional Certificate/ Diploma\",\n",
    "\"University Degree\",\n",
    "\"Masters Degree\",\n",
    "\"Doctorate Degree\"]\n",
    "Education_map = dict(zip(sorted(df[cat_cols[2]].unique()), education_groups))\n",
    "Education_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fb5650-5c4a-4c62-a43a-02053c289aa1",
   "metadata": {},
   "source": [
    "### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "49b38f52-024f-4735-a360-24dbbb1a0f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-0.09765: 'Australia',\n",
       " 0.24923: 'Canada',\n",
       " -0.46841: 'New Zealan',\n",
       " -0.28519: 'Other',\n",
       " 0.21128: 'Republic of Ireland',\n",
       " 0.96082: 'UK',\n",
       " -0.57009: 'USA'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Country_map = {-0.09765 : \"Australia\",\n",
    "0.24923 : \"Canada\",\n",
    "-0.46841 : \"New Zealan\",\n",
    "-0.28519 : \"Other\",\n",
    "0.21128 : \"Republic of Ireland\",\n",
    "0.96082 : \"UK\",\n",
    "-0.57009 : \"USA\"}\n",
    "Country_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c324c6-6014-437b-81aa-1130e06f3174",
   "metadata": {},
   "source": [
    "### Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d284f627-c9c5-41fb-a921-9736afd9ecc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-0.50212: 'Asian',\n",
       " -1.10702: 'Black',\n",
       " 1.90725: 'Mixed-Black/Asian',\n",
       " 0.126: 'Mixed-White/Asian',\n",
       " -0.22166: 'Mixed-White/Black',\n",
       " 0.1144: 'Other',\n",
       " -0.31685: 'White'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ethnicity_map  = {-0.50212 : \"Asian\",\n",
    "-1.10702 : \"Black\",\n",
    "1.90725 : \"Mixed-Black/Asian\",\n",
    "0.12600 : \"Mixed-White/Asian\",\n",
    "-0.22166 : \"Mixed-White/Black\",\n",
    "0.11440 : \"Other\",\n",
    "-0.31685 : \"White\"}\n",
    "Ethnicity_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "88c85462-c4ab-4a8a-8371-f66118e81261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CL0': 'Never Used',\n",
       " 'CL1': 'Used over a Decade Ago',\n",
       " 'CL2': 'Used in Last Decade',\n",
       " 'CL3': 'Used in Last Year',\n",
       " 'CL4': 'Used in Last Month',\n",
       " 'CL5': 'Used in Last Week',\n",
       " 'CL6': 'Used in Last Day'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Label_map = {\"CL0\" : \"Never Used\",\n",
    "\"CL1\" : \"Used over a Decade Ago\",\n",
    "\"CL2\" : \"Used in Last Decade\",\n",
    "\"CL3\" : \"Used in Last Year\",\n",
    "\"CL4\" : \"Used in Last Month\",\n",
    "\"CL5\" : \"Used in Last Week\",\n",
    "\"CL6\" : \"Used in Last Day\"}\n",
    "Label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a99fd59c-2882-46e0-a5e1-6e7fdfbb1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = [Age_map, Gender_map, Education_map, Country_map, Ethnicity_map]\n",
    "\n",
    "for i, j in enumerate(maps):\n",
    "    df[cat_cols[i]] = df[cat_cols[i]].map(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6f857359-8be7-4899-a81c-50f1a3b4fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Semer\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1283e67d-c41e-4f5c-8e68-5631045734fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['18 - 24', '25 - 34', '35 - 44', '45 - 54', '55+'], dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a5cff6ca-6d7b-40d7-b77a-172801dd128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"] = df[\"Age\"].replace({'65+' : '55 - 64'})\n",
    "df[\"Age\"] = df[\"Age\"].replace({'55 - 64' : '55+'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a9a0285-2c67-43e9-b232-d76005d3582f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age           object\n",
       "Gender        object\n",
       "Education     object\n",
       "Country       object\n",
       "Ethnicity     object\n",
       "Nscore       float64\n",
       "Escore       float64\n",
       "Oscore       float64\n",
       "Ascore       float64\n",
       "Cscore       float64\n",
       "Impulsive    float64\n",
       "SS           float64\n",
       "Alcohol       object\n",
       "Amphet        object\n",
       "Amyl          object\n",
       "Benzos        object\n",
       "Caff          object\n",
       "Cannabis      object\n",
       "Choc          object\n",
       "Coke          object\n",
       "Crack         object\n",
       "Ecstasy       object\n",
       "Heroin        object\n",
       "Ketamine      object\n",
       "Legalh        object\n",
       "LSD           object\n",
       "Meth          object\n",
       "Mushrooms     object\n",
       "Nicotine      object\n",
       "VSA           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "960c5418-4961-438d-afeb-8955aa81d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## df.to_csv(\"drug.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cc0b1720-4111-4dc6-a976-658bc0349171",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cols = df.iloc[:, 5:(5+7)].columns\n",
    "demo_cols = df.iloc[:, :5].columns\n",
    "drug_cols = df.iloc[:, 12:].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5fbd72-d7ec-434c-ab66-496abf55e8b4",
   "metadata": {},
   "source": [
    "## multi_label_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0ac6f2db-ab3e-4e71-97ab-a3a360e9f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malis\\AppData\\Local\\Temp\\ipykernel_1484\\3020773583.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = df[drug_cols].replace(dict(zip(np.unique(y), np.array([0, 0, 0, 1, 1, 1, 1]))))\n"
     ]
    }
   ],
   "source": [
    "X = df[score_cols]\n",
    "y = df[drug_cols].replace(dict(zip(np.unique(y), np.array([0, 0, 0, 1, 1, 1, 1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c10c3007-2787-4d93-8856-59c0eb418040",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6d781481-f6f4-42c2-b33e-1c273d3c796d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1508, 7), (377, 7))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "0d306109-bdd4-4c4b-af27-410579db9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_units):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_units)\n",
    "        self.layer2 = nn.Linear(hidden_units, hidden_units)\n",
    "        self.output = nn.Linear(hidden_units, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.output(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "5796d577-98d7-4f90-9edd-99dee34990d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nscore</th>\n",
       "      <th>Escore</th>\n",
       "      <th>Oscore</th>\n",
       "      <th>Ascore</th>\n",
       "      <th>Cscore</th>\n",
       "      <th>Impulsive</th>\n",
       "      <th>SS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>-0.05188</td>\n",
       "      <td>-1.23177</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.25953</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>0.76540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>0.52135</td>\n",
       "      <td>0.32197</td>\n",
       "      <td>0.72330</td>\n",
       "      <td>0.13136</td>\n",
       "      <td>1.13407</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.52593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>-0.24649</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>1.06238</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>2.04506</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.52593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>-0.05188</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.88309</td>\n",
       "      <td>0.13136</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>0.07987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>2.28554</td>\n",
       "      <td>-1.23177</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>-2.53830</td>\n",
       "      <td>-2.90161</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>1.22470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>0.62967</td>\n",
       "      <td>-0.69509</td>\n",
       "      <td>0.14143</td>\n",
       "      <td>-1.21213</td>\n",
       "      <td>-0.27607</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>-0.34799</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>-0.15487</td>\n",
       "      <td>-0.52745</td>\n",
       "      <td>0.19268</td>\n",
       "      <td>1.22470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.04257</td>\n",
       "      <td>-0.15487</td>\n",
       "      <td>-0.17779</td>\n",
       "      <td>-0.60633</td>\n",
       "      <td>-0.40581</td>\n",
       "      <td>1.86203</td>\n",
       "      <td>1.22470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0.13606</td>\n",
       "      <td>0.16767</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>0.43852</td>\n",
       "      <td>0.12331</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>0.40148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1.02119</td>\n",
       "      <td>-2.03972</td>\n",
       "      <td>-0.71727</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>-1.25773</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>0.40148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1508 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nscore   Escore   Oscore   Ascore   Cscore  Impulsive       SS\n",
       "1814 -0.05188 -1.23177  0.29338  1.11406  0.25953    0.88113  0.76540\n",
       "710   0.52135  0.32197  0.72330  0.13136  1.13407   -0.21712 -0.52593\n",
       "931  -0.24649  0.00332  1.06238  0.59042  2.04506   -0.71126 -0.52593\n",
       "617  -0.05188  1.11406  0.88309  0.13136 -0.00665    0.52975  0.07987\n",
       "1797  2.28554 -1.23177 -0.01928 -2.53830 -2.90161   -0.21712  1.22470\n",
       "...       ...      ...      ...      ...      ...        ...      ...\n",
       "1130  0.62967 -0.69509  0.14143 -1.21213 -0.27607   -0.21712 -0.21575\n",
       "1294 -0.34799  0.00332  0.58331 -0.15487 -0.52745    0.19268  1.22470\n",
       "860   0.04257 -0.15487 -0.17779 -0.60633 -0.40581    1.86203  1.22470\n",
       "1459  0.13606  0.16767 -0.45174  0.43852  0.12331   -0.71126  0.40148\n",
       "1126  1.02119 -2.03972 -0.71727  1.11406 -1.25773    0.88113  0.40148\n",
       "\n",
       "[1508 rows x 7 columns]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "ccd1322a-da08-4f5b-892e-726e98aa52e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.to_numpy(), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "d332bbb6-9978-449e-bbc1-dccba0e41c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.dtype, y_train_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "dac4409c-2674-45a7-869b-b30857f511e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "61f2d80a-678e-4c30-9ffe-2ac7f2ad78fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "ca035152-fdd3-4c71-a6b5-5217eeca7d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].dtype, next(iter(train_dataloader))[1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "0463e7ad-7097-4633-a11f-37f0c37189b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]\n",
    "output_shape = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "9b79f331-b9ba-4b9c-bbcb-c329a8f43221",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_shape, output_shape, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "ceef28d7-73d2-4360-864f-926952900667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layer1): Linear(in_features=7, out_features=30, bias=True)\n",
       "  (layer2): Linear(in_features=30, out_features=30, bias=True)\n",
       "  (output): Linear(in_features=30, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "e040f06c-2334-4f70-835f-e51e33f0c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "3a7ebe8a-deca-40e7-b92f-c9586ce8f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    y_pred = y_pred.round()\n",
    "    correct = (y_pred == y_true).float()  # Get a tensor of 1s and 0s\n",
    "    acc = correct.sum() / correct.numel()  # Mean of correct predictions\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "3deb9f30-f8e5-4546-aa4c-d2f188a8f8cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c615d7db85bc491cb14d6a0ee1d289df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.6272293925285339 | train acc: 0.7055122256278992 | val loss: 0.5290291905403137 | val acc: 0.8164758086204529\n",
      "\n",
      "Epoch: 1 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.45716598629951477 | train acc: 0.8192636370658875 | val loss: 0.4159373939037323 | val acc: 0.8303298950195312\n",
      "\n",
      "Epoch: 2 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3993009328842163 | train acc: 0.8334056735038757 | val loss: 0.3951549828052521 | val acc: 0.8285995125770569\n",
      "\n",
      "Epoch: 3 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.38230302929878235 | train acc: 0.8381075859069824 | val loss: 0.3873380422592163 | val acc: 0.8305151462554932\n",
      "\n",
      "Epoch: 4 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3718971014022827 | train acc: 0.8412181735038757 | val loss: 0.3804565966129303 | val acc: 0.8325464129447937\n",
      "\n",
      "Epoch: 5 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.36980676651000977 | train acc: 0.8408203125 | val loss: 0.377865195274353 | val acc: 0.8340856432914734\n",
      "\n",
      "Epoch: 6 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.36569762229919434 | train acc: 0.841905415058136 | val loss: 0.37918904423713684 | val acc: 0.8317997455596924\n",
      "\n",
      "Epoch: 7 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3653387725353241 | train acc: 0.8425564765930176 | val loss: 0.3741510808467865 | val acc: 0.8321759700775146\n",
      "\n",
      "Epoch: 8 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3617948293685913 | train acc: 0.8417969346046448 | val loss: 0.3715761601924896 | val acc: 0.8347627520561218\n",
      "\n",
      "Epoch: 9 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3616273105144501 | train acc: 0.8429181575775146 | val loss: 0.374241441488266 | val acc: 0.8331307768821716\n",
      "\n",
      "Epoch: 10 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3592914342880249 | train acc: 0.8423755764961243 | val loss: 0.3714965581893921 | val acc: 0.8350868225097656\n",
      "\n",
      "Epoch: 11 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3603721857070923 | train acc: 0.8416883945465088 | val loss: 0.3704034388065338 | val acc: 0.835613489151001\n",
      "\n",
      "Epoch: 12 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.35421276092529297 | train acc: 0.8447627425193787 | val loss: 0.3692586123943329 | val acc: 0.8364005088806152\n",
      "\n",
      "Epoch: 13 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.357959508895874 | train acc: 0.8430265784263611 | val loss: 0.36790037155151367 | val acc: 0.8369328379631042\n",
      "\n",
      "Epoch: 14 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.35642167925834656 | train acc: 0.843858540058136 | val loss: 0.37001267075538635 | val acc: 0.8359549045562744\n",
      "\n",
      "Epoch: 15 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3541019856929779 | train acc: 0.844835102558136 | val loss: 0.3684828281402588 | val acc: 0.8378761410713196\n",
      "\n",
      "Epoch: 16 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.35697779059410095 | train acc: 0.8438223004341125 | val loss: 0.3697940409183502 | val acc: 0.8369502425193787\n",
      "\n",
      "Epoch: 17 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3550480306148529 | train acc: 0.8448349833488464 | val loss: 0.3681877553462982 | val acc: 0.8368346095085144\n",
      "\n",
      "Epoch: 18 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.35314127802848816 | train acc: 0.8455583453178406 | val loss: 0.36699697375297546 | val acc: 0.8368403315544128\n",
      "\n",
      "Epoch: 19 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.35117146372795105 | train acc: 0.8469690680503845 | val loss: 0.3668835461139679 | val acc: 0.8383622765541077\n",
      "\n",
      "Epoch: 20 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3651171922683716 | train acc: 0.8415436744689941 | val loss: 0.36891868710517883 | val acc: 0.8373379707336426\n",
      "\n",
      "Epoch: 21 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3575633764266968 | train acc: 0.8432073593139648 | val loss: 0.3688782751560211 | val acc: 0.837054431438446\n",
      "\n",
      "Epoch: 22 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3500843048095703 | train acc: 0.8473308086395264 | val loss: 0.3697122037410736 | val acc: 0.8366608619689941\n",
      "\n",
      "Epoch: 23 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3550562858581543 | train acc: 0.8454861044883728 | val loss: 0.36626577377319336 | val acc: 0.8393170833587646\n",
      "\n",
      "Epoch: 24 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.35353755950927734 | train acc: 0.8464266657829285 | val loss: 0.3680253326892853 | val acc: 0.8375751972198486\n",
      "\n",
      "Epoch: 25 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3496570289134979 | train acc: 0.8481264710426331 | val loss: 0.3685166537761688 | val acc: 0.838761568069458\n",
      "\n",
      "Epoch: 26 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.353757381439209 | train acc: 0.8445457816123962 | val loss: 0.3660452663898468 | val acc: 0.8383216857910156\n",
      "\n",
      "Epoch: 27 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.35015782713890076 | train acc: 0.847113847732544 | val loss: 0.3658616542816162 | val acc: 0.8394154906272888\n",
      "\n",
      "Epoch: 28 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3520689904689789 | train acc: 0.8469329476356506 | val loss: 0.36622023582458496 | val acc: 0.8381829261779785\n",
      "\n",
      "Epoch: 29 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34975466132164 | train acc: 0.8469688892364502 | val loss: 0.36826083064079285 | val acc: 0.8383391499519348\n",
      "\n",
      "Epoch: 30 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3513178825378418 | train acc: 0.8468604683876038 | val loss: 0.36587604880332947 | val acc: 0.8387730717658997\n",
      "\n",
      "Epoch: 31 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.35121598839759827 | train acc: 0.8480179309844971 | val loss: 0.3674475848674774 | val acc: 0.8379976749420166\n",
      "\n",
      "Epoch: 32 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34842780232429504 | train acc: 0.8489944934844971 | val loss: 0.367291659116745 | val acc: 0.8394386768341064\n",
      "\n",
      "Epoch: 33 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3491426706314087 | train acc: 0.8470051884651184 | val loss: 0.3654698431491852 | val acc: 0.8399074077606201\n",
      "\n",
      "Epoch: 34 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3493647575378418 | train acc: 0.8485966324806213 | val loss: 0.3682703971862793 | val acc: 0.8381307721138\n",
      "\n",
      "Epoch: 35 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3475089371204376 | train acc: 0.8480179905891418 | val loss: 0.36680546402931213 | val acc: 0.8389583230018616\n",
      "\n",
      "Epoch: 36 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.35082435607910156 | train acc: 0.847366988658905 | val loss: 0.3668576180934906 | val acc: 0.8383390307426453\n",
      "\n",
      "Epoch: 37 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3497382700443268 | train acc: 0.847764790058136 | val loss: 0.3657067120075226 | val acc: 0.8390626311302185\n",
      "\n",
      "Epoch: 38 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3504033386707306 | train acc: 0.8464989066123962 | val loss: 0.36735427379608154 | val acc: 0.8393924236297607\n",
      "\n",
      "Epoch: 39 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34769296646118164 | train acc: 0.8491752743721008 | val loss: 0.36575397849082947 | val acc: 0.8400578498840332\n",
      "\n",
      "Epoch: 40 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3501688241958618 | train acc: 0.8484518527984619 | val loss: 0.3664904832839966 | val acc: 0.8390682339668274\n",
      "\n",
      "Epoch: 41 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3502797782421112 | train acc: 0.8480177521705627 | val loss: 0.3664904832839966 | val acc: 0.8391261100769043\n",
      "\n",
      "Epoch: 42 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34771546721458435 | train acc: 0.8479095101356506 | val loss: 0.3674866259098053 | val acc: 0.8383796215057373\n",
      "\n",
      "Epoch: 43 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34486496448516846 | train acc: 0.8509113788604736 | val loss: 0.36687150597572327 | val acc: 0.8383622765541077\n",
      "\n",
      "Epoch: 44 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3476283848285675 | train acc: 0.8494284749031067 | val loss: 0.36649689078330994 | val acc: 0.8368575572967529\n",
      "\n",
      "Epoch: 45 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3475334644317627 | train acc: 0.8501157760620117 | val loss: 0.3674520254135132 | val acc: 0.8393287658691406\n",
      "\n",
      "Epoch: 46 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34730151295661926 | train acc: 0.8484517931938171 | val loss: 0.36415717005729675 | val acc: 0.8419733047485352\n",
      "\n",
      "Epoch: 47 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34798362851142883 | train acc: 0.8487050533294678 | val loss: 0.3662376403808594 | val acc: 0.8394966125488281\n",
      "\n",
      "Epoch: 48 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3476046025753021 | train acc: 0.8499710559844971 | val loss: 0.36603355407714844 | val acc: 0.8406481742858887\n",
      "\n",
      "Epoch: 49 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34500786662101746 | train acc: 0.8512370586395264 | val loss: 0.36922529339790344 | val acc: 0.8373900055885315\n",
      "\n",
      "Epoch: 50 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3469819724559784 | train acc: 0.8491029143333435 | val loss: 0.36648595333099365 | val acc: 0.8385764956474304\n",
      "\n",
      "Epoch: 51 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3449007570743561 | train acc: 0.8507307171821594 | val loss: 0.36783960461616516 | val acc: 0.8387789130210876\n",
      "\n",
      "Epoch: 52 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3472648561000824 | train acc: 0.8496094346046448 | val loss: 0.36679700016975403 | val acc: 0.839623749256134\n",
      "\n",
      "Epoch: 53 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3475963771343231 | train acc: 0.849609375 | val loss: 0.3663932979106903 | val acc: 0.8391146659851074\n",
      "\n",
      "Epoch: 54 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3446462154388428 | train acc: 0.851453959941864 | val loss: 0.36825039982795715 | val acc: 0.8370370864868164\n",
      "\n",
      "Epoch: 55 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3430698812007904 | train acc: 0.8520326018333435 | val loss: 0.36780497431755066 | val acc: 0.8395833969116211\n",
      "\n",
      "Epoch: 56 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34373679757118225 | train acc: 0.8525391221046448 | val loss: 0.3678484261035919 | val acc: 0.8386862874031067\n",
      "\n",
      "Epoch: 57 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34350407123565674 | train acc: 0.8526837825775146 | val loss: 0.36869385838508606 | val acc: 0.8374421000480652\n",
      "\n",
      "Epoch: 58 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3433934450149536 | train acc: 0.8524305820465088 | val loss: 0.36684510111808777 | val acc: 0.839809000492096\n",
      "\n",
      "Epoch: 59 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34806761145591736 | train acc: 0.8494646549224854 | val loss: 0.3687226474285126 | val acc: 0.8392534255981445\n",
      "\n",
      "Epoch: 60 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34419703483581543 | train acc: 0.8516349792480469 | val loss: 0.3700698912143707 | val acc: 0.8384549021720886\n",
      "\n",
      "Epoch: 61 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3438986539840698 | train acc: 0.8506945967674255 | val loss: 0.36617031693458557 | val acc: 0.8401504158973694\n",
      "\n",
      "Epoch: 62 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.35052910447120667 | train acc: 0.8474753499031067 | val loss: 0.3726418912410736 | val acc: 0.8359549045562744\n",
      "\n",
      "Epoch: 63 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3450535833835602 | train acc: 0.8506944179534912 | val loss: 0.36766448616981506 | val acc: 0.838883101940155\n",
      "\n",
      "Epoch: 64 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34422704577445984 | train acc: 0.8522858619689941 | val loss: 0.36732134222984314 | val acc: 0.8376100063323975\n",
      "\n",
      "Epoch: 65 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34477436542510986 | train acc: 0.8506221175193787 | val loss: 0.3686659336090088 | val acc: 0.8370949625968933\n",
      "\n",
      "Epoch: 66 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34416136145591736 | train acc: 0.8509836792945862 | val loss: 0.3685578405857086 | val acc: 0.838217556476593\n",
      "\n",
      "Epoch: 67 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34399494528770447 | train acc: 0.8517434000968933 | val loss: 0.36813679337501526 | val acc: 0.8391377925872803\n",
      "\n",
      "Epoch: 68 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3459356725215912 | train acc: 0.850405216217041 | val loss: 0.36731719970703125 | val acc: 0.8399768471717834\n",
      "\n",
      "Epoch: 69 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3413500487804413 | train acc: 0.8519241213798523 | val loss: 0.36930620670318604 | val acc: 0.8373148441314697\n",
      "\n",
      "Epoch: 70 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34265971183776855 | train acc: 0.8528645634651184 | val loss: 0.3671921491622925 | val acc: 0.8384143710136414\n",
      "\n",
      "Epoch: 71 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34320536255836487 | train acc: 0.8523220419883728 | val loss: 0.36684104800224304 | val acc: 0.8389294147491455\n",
      "\n",
      "Epoch: 72 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34459352493286133 | train acc: 0.8512731194496155 | val loss: 0.36917176842689514 | val acc: 0.8392071723937988\n",
      "\n",
      "Epoch: 73 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3461618423461914 | train acc: 0.8507667183876038 | val loss: 0.36783477663993835 | val acc: 0.8399016261100769\n",
      "\n",
      "Epoch: 74 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3441005051136017 | train acc: 0.8523219227790833 | val loss: 0.366326242685318 | val acc: 0.8393981456756592\n",
      "\n",
      "Epoch: 75 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34092557430267334 | train acc: 0.8534433841705322 | val loss: 0.3696011006832123 | val acc: 0.8380903601646423\n",
      "\n",
      "Epoch: 76 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3427205979824066 | train acc: 0.851851761341095 | val loss: 0.3687317669391632 | val acc: 0.8380267024040222\n",
      "\n",
      "Epoch: 77 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3412635028362274 | train acc: 0.8522859215736389 | val loss: 0.3694635331630707 | val acc: 0.8369618058204651\n",
      "\n",
      "Epoch: 78 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3426075875759125 | train acc: 0.8521411418914795 | val loss: 0.3687663972377777 | val acc: 0.838391125202179\n",
      "\n",
      "Epoch: 79 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34150230884552 | train acc: 0.8520689010620117 | val loss: 0.3675762414932251 | val acc: 0.8382408022880554\n",
      "\n",
      "Epoch: 80 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34237322211265564 | train acc: 0.8519602417945862 | val loss: 0.3722369968891144 | val acc: 0.8372165560722351\n",
      "\n",
      "Epoch: 81 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34132659435272217 | train acc: 0.8523221015930176 | val loss: 0.36972904205322266 | val acc: 0.8385995030403137\n",
      "\n",
      "Epoch: 82 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3406194746494293 | train acc: 0.8534793257713318 | val loss: 0.3702395260334015 | val acc: 0.8386111259460449\n",
      "\n",
      "Epoch: 83 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34078142046928406 | train acc: 0.8530455231666565 | val loss: 0.36659422516822815 | val acc: 0.8386284708976746\n",
      "\n",
      "Epoch: 84 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34401199221611023 | train acc: 0.8517794013023376 | val loss: 0.3679731786251068 | val acc: 0.8395254611968994\n",
      "\n",
      "Epoch: 85 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34093141555786133 | train acc: 0.8531179428100586 | val loss: 0.3689761459827423 | val acc: 0.838524341583252\n",
      "\n",
      "Epoch: 86 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34305450320243835 | train acc: 0.8511645197868347 | val loss: 0.3691108226776123 | val acc: 0.8376272320747375\n",
      "\n",
      "Epoch: 87 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.33927062153816223 | train acc: 0.8539135456085205 | val loss: 0.3673781156539917 | val acc: 0.841249942779541\n",
      "\n",
      "Epoch: 88 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.344950407743454 | train acc: 0.8512007594108582 | val loss: 0.3686121702194214 | val acc: 0.8385011553764343\n",
      "\n",
      "Epoch: 89 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3396589457988739 | train acc: 0.8535156846046448 | val loss: 0.36938536167144775 | val acc: 0.8377198576927185\n",
      "\n",
      "Epoch: 90 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34166190028190613 | train acc: 0.8521773815155029 | val loss: 0.3690892159938812 | val acc: 0.8395138382911682\n",
      "\n",
      "Epoch: 91 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3390556275844574 | train acc: 0.8540582060813904 | val loss: 0.3671513497829437 | val acc: 0.8399362564086914\n",
      "\n",
      "Epoch: 92 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3409801423549652 | train acc: 0.8527922630310059 | val loss: 0.3673492670059204 | val acc: 0.8380439877510071\n",
      "\n",
      "Epoch: 93 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34027254581451416 | train acc: 0.8535880446434021 | val loss: 0.36956843733787537 | val acc: 0.8377777934074402\n",
      "\n",
      "Epoch: 94 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34057366847991943 | train acc: 0.8530091643333435 | val loss: 0.3676743805408478 | val acc: 0.8390335440635681\n",
      "\n",
      "Epoch: 95 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.3406117260456085 | train acc: 0.8530092239379883 | val loss: 0.36884161829948425 | val acc: 0.8384721875190735\n",
      "\n",
      "Epoch: 96 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.33955201506614685 | train acc: 0.853624165058136 | val loss: 0.36863139271736145 | val acc: 0.8379282355308533\n",
      "\n",
      "Epoch: 97 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.34199485182762146 | train acc: 0.8517072200775146 | val loss: 0.37002333998680115 | val acc: 0.8374767899513245\n",
      "\n",
      "Epoch: 98 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.33872392773628235 | train acc: 0.8535879254341125 | val loss: 0.36818018555641174 | val acc: 0.8396122455596924\n",
      "\n",
      "Epoch: 99 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.33949020504951477 | train acc: 0.852973222732544 | val loss: 0.36745119094848633 | val acc: 0.8401215076446533\n",
      "\n",
      "\n",
      "train time: 14.694152500014752\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "start = timer()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch} \\n ---------\")\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        train_acc += accuracy(y, y_pred)\n",
    "\n",
    "        train_loss += loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            print(f\"looked at {batch * len(X)} / {len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y, in test_dataloader:\n",
    "\n",
    "            test_pred = model(X)\n",
    "\n",
    "            test_acc += accuracy(y, test_pred)\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"\\ntrain loss: {train_loss} | train acc: {train_acc} | val loss: {test_loss} | val acc: {test_acc}\\n\")\n",
    "\n",
    "            \n",
    "end = timer()\n",
    "print_train_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea38370-dc09-417c-a4eb-e416458a434e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2a9038-090f-4146-bd42-4e2f85092a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390ef3b-5bcb-400f-95c0-9115ddcec67c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
